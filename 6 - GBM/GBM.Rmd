---
title: "GBM"
output:
  github_document:
        toc: true
  html_document:
    toc: true
    toc_float: true
    number_sections: true    
    theme: united
    highlight: tango
    code_folding: show
    keep_md: false
---

#Introduction 

We can start by loading the packages.
```{r, warning=FALSE, message=FALSE, tidy=TRUE}
require(devtools)
install_github("gbm-developers/gbm3")

library(gbm3)
library(caret)
library(mgcv)
library(reshape2)
library(ggplot2)
library(dplyr)
```

We can also load the data (same as in the previous sessions).
```{r, tidy=TRUE, message=FALSE, warning=FALSE}
## Loading the dataset
# require("CASdatasets")
# data("freMTPLfreq")
# 
# freMTPLfreq = subset(freMTPLfreq, Exposure<=1 & Exposure >= 0 & CarAge<=25)
# 
# set.seed(85)
# folds = createDataPartition(freMTPLfreq$ClaimNb, 0.5)
# dataset = freMTPLfreq[folds[[1]], ]
dataset = readRDS("../dataset.RDS")

set.seed(21)
in_training = createDataPartition(dataset$ClaimNb, times = 1, p = 0.8, list=FALSE)
training_set = dataset[in_training,]
testing_set  = dataset[-in_training,]
```

# GBM3

The *gbm3* package is very similar to the package *gbm* available on CRAN. However, the gbm package is now an orphan, while the gbm3 package is basically an enhanced version of the *gbm* package and is maintained.

We have several distributions available in the *gbm3* packages:
```{r, tidy=TRUE}
available_distributions()
```


## Small Example with two variables.

The main function is *gbmt*.

```{r, message=FALSE, tidy=FALSE, fig.align='center', dpi=500}
set.seed(1)
m0 = gbmt(ClaimNb ~ offset(log(Exposure)) + CarAge + DriverAge,
         data = training_set,
         distribution = gbm_dist("Poisson"),
         train_params = training_params(num_trees = 100,
                                        shrinkage = 0.01, #Default is 0.001
                                        interaction_depth = 5,  #the max number of non-terminal nodes in each tree 
                                        min_num_obs_in_node = 1000,
                                        bag_fraction = 0.5, # At each tree, only 50% of the data is considered
                                        num_train = 0.5*nrow(training_set)), #50% of the training set will be used in the learning process
         is_verbose = TRUE,
         keep_gbm_data = TRUE,
         par_details = gbmParallel(num_threads = 3)) #Parallel computing
m0
```

We can find the optimal number of trees using gbmt_performance.
```{r, tidy=TRUE, fig.align='center', dpi=500}
gbmt_performance(m0, method="OOB")
```

Sometimes the GBM won't have enough trees. This can be seen when the optimal number of trees equals to total number of trees.
No need to rerun everything, we can just add some new trees.

```{r, tidy=TRUE, fig.align='center', dpi=500}
set.seed(2)
m1 = gbm_more(m0, num_new_trees = 400, is_verbose = TRUE)
```


We can check the optimal number of trees based on the out-of-bag observations.

```{r}
gbmt_performance(m1, method="OOB")
```

It is however better to perform cross-validation to find the optimal number of boosting iterations.
```{r, cache=TRUE, tidy=FALSE, fig.align='center', dpi=500}
set.seed(1)
m0 = gbmt(ClaimNb ~ offset(log(Exposure)) + CarAge + DriverAge,
         data = training_set,
         distribution = gbm_dist("Poisson"),
         train_params = training_params(num_trees = 400,
                                        shrinkage = 0.01, #Default is 0.001
                                        interaction_depth = 5,  #the max number of non-terminal nodes in each tree 
                                        min_num_obs_in_node = 1000,
                                        bag_fraction = 0.5,
                                        num_train = 1*nrow(training_set)),
         is_verbose = TRUE,
         keep_gbm_data = TRUE,
         cv_folds = 5,
         par_details = gbmParallel(num_threads = 3)) #Parallel computing
m0
```

Here, with cv, unfortunately, we cannot add more trees.
We can plot the deviance as a function of the number of trees.
```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(gbmt_performance(m0, method="cv"))
```

To get the numerical value,
```{r, tidy=TRUE, fig.align='center', dpi=500}
best_iter = gbmt_performance(m0, method="cv")
best_iter
```
The cross-validation error can be retrieved.
```{r}
m0$cv_error[gbmt_performance(m0, method="cv")] # or m0$cv_error[best_iter]
```



Let's see the variable influence.

```{r, tidy=TRUE, fig.align='center', dpi=500}
summary(m0, num_trees = best_iter)
```

We can plot the partial dependencies of the variables.

```{r, tidy=TRUE, fig.align='center', dpi=500}
par(mfrow=c(1,2))
plot(m0, var_index = 1, num_trees = best_iter, type="response")
plot(m0, var_index = 2, num_trees = best_iter, type="response")
```


When we are finished, we can evaluate the performance of the model on the validation set.

```{r, tidy=TRUE, fig.align='center', dpi=500}
2*(sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb,log=TRUE))-
  sum(dpois(x = testing_set$ClaimNb, lambda = predict(m0,newdata = testing_set,n.trees=best_iter, type="response") * testing_set$Exposure,
            log=TRUE)))
```
We can take a look at the first tree, using the *pretty_gbm_tree* function.

```{r}
pretty_gbm_tree(m0, tree_index =1) %>% 
  filter(SplitVar != -1) # Only keep non terminal nodes
```

## Using all the variables

```{r, cache=TRUE, tidy=FALSE, fig.align='center', dpi=500}
set.seed(89)
m0_gbm = gbmt(ClaimNb ~ offset(log(Exposure)) + CarAge + DriverAge + Power + Brand + Gas + Region + Density,
         data = training_set,
         distribution = gbm_dist("Poisson"),
         train_params = training_params(num_trees = 500,
                                        shrinkage = 0.01, #Default is 0.001
                                        interaction_depth = 5,  #the max number of non - terminal nodes in each tree 
                                        min_num_obs_in_node = 1000,
                                        num_train = 1*nrow(training_set)),
         is_verbose = TRUE,
         keep_gbm_data = TRUE,
         par_details = gbmParallel(num_threads = 3)) #Parallel computing
m0_gbm
```

We can, using the OOB, find the optimal number of iterations.

```{r, tidy=TRUE, fig.align='center', dpi=500}
gbmt_performance(m0_gbm)
```

```{r, tidy=TRUE, fig.align='center', dpi=500}
m1_gbm = gbm_more(m0_gbm, num_new_trees = 500, is_verbose = TRUE)
```

Checking the performance now..
```{r, tidy=TRUE, fig.align='center', dpi=500}
gbmt_performance(m1_gbm)
```

Let's now perform the cross-validation with 1000 trees. (~ 6 minutes)
```{r, cache=TRUE, tidy=FALSE, fig.align='center', dpi=500}
set.seed(89)
m0_gbm = gbmt(ClaimNb ~ offset(log(Exposure)) + CarAge + DriverAge + Power + Brand + Gas + Region + Density,
         data = training_set,
         distribution = gbm_dist("Poisson"),
         train_params = training_params(num_trees = 1000,
                                        shrinkage = 0.01, #Default is 0.001
                                        interaction_depth = 5,  #the max number of non - terminal nodes in each tree 
                                        min_num_obs_in_node = 1000,
                                        bag_fraction = 0.5,
                                        num_train = 1*nrow(training_set)),
         is_verbose = TRUE,
         cv_folds = 5,
         keep_gbm_data = TRUE,
         par_details = gbmParallel(num_threads = 3)) #Parallel computing
m0_gbm
```

Let's now plot the performance.
```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(gbmt_performance(m0_gbm), method="cv")
```

```{r, tidy=TRUE, fig.align='center', dpi=500}
best_iter = gbmt_performance(m0_gbm, "cv")
best_iter
```

We can see the variable importance.
```{r, tidy=TRUE, fig.align='center', dpi=500}
summary(m0_gbm)
```

We can take a look at the partial dependencies.

```{r, fig.height=5, fig.width = 10, tidy=TRUE, fig.align='center', dpi=500}
par(mfrow=c(2,4))
for (i in 1:7){
  plot(m0_gbm, var_index = i, num_trees = best_iter, type="response")
}
```

Let's compute Friedman's H statistic for interaction, for all the possible couple of variable.

```{r, tidy=TRUE, fig.align='center', dpi=500}
var_names = c("CarAge", "DriverAge", "Power", "Brand","Gas", "Region", "Density" )

res = matrix(NA, 7,7)
for (i in 1:6){
  for (j in (i+1):7){
    res[i,j] = interact(gbm_fit_obj = m0_gbm, data=training_set, var_indices = c(i,j), best_iter)
  }
}
diag(res) = 0
row.names(res) = var_names
colnames(res) = row.names(res)

interact_melt<-melt(res,na.rm = TRUE)

ggplot(data = interact_melt, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "white", mid = "gray", high = "blue",name="Friedman's\nH-statistic") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()
```
Let us plot the partial dependencies of some of these variables.

```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(m0_gbm, var_index = c(which(var_names == "Gas"), which(var_names == "Power")), num_trees = best_iter, type="response") #Power, Gas
```
```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(m0_gbm, var_index = c(which(var_names == "Gas"), which(var_names == "Region")), num_trees = best_iter, type="response") # Gas, Region
```


```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(m0_gbm, var_index = c(which(var_names == "Brand"), which(var_names == "CarAge")), num_trees = best_iter, type="response") 
```

```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(m0_gbm, var_index = c(which(var_names == "Power"), which(var_names == "Brand")), num_trees = best_iter, type="response") # Gas, Region
```


```{r, tidy=TRUE, fig.align='center', dpi=500}
plot(m0_gbm, var_index = c(which(var_names == "CarAge"), which(var_names == "DriverAge")), num_trees = best_iter, type="response") # Gas, Region
```

We can check the power of prediction of the model.
```{r, warning=FALSE, tidy=TRUE}
2*(sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb,log=TRUE))-
  sum(dpois(x = testing_set$ClaimNb, lambda = predict(m0_gbm,newdata = testing_set,n.trees=best_iter, type="response") * testing_set$Exposure,
            log=TRUE)))
```

## Tweaking the model

We would have to tweak the parameters. We should define a grid of parameters and perform cross-validation to choose the optimal parameters. Due to time restriction, we will only show one example, for instance : 

```{r, cache=TRUE, tidy=FALSE}
set.seed(89)
m1_gbm = gbmt(ClaimNb ~ offset(log(Exposure)) + CarAge + DriverAge + Power + Brand + Gas + Region + Density,
         data = training_set,
         distribution = gbm_dist("Poisson"),
         train_params = training_params(num_trees = 1000,
                                        shrinkage = 0.01, #Default is 0.001
                                        interaction_depth = 10,  #the max number of non-terminal nodes in each tree 
                                        min_num_obs_in_node = 1000,
                                        num_train = 1*nrow(training_set)),
         is_verbose = FALSE,
         cv_folds = 5,
         par_details = gbmParallel(num_threads = 3)) #Parallel computing
m1_gbm
```

Let's take a look at the performance.
```{r, dpi=500, fig.align='center', tidy=TRUE}
plot(gbmt_performance(m1_gbm, method="cv"))
```


Let's compare both cross-validation errors.
```{r}
c(min(m0_gbm$cv_error),min(m1_gbm$cv_error))
```

The difference seems small... however, if we look at the predictions..

```{r, warning=FALSE, tidy=FALSE, fig.align='center', dpi=500}
require(ggplot2)
ggplot() + 
  geom_histogram(aes(x=predict(m0_gbm,newdata = training_set,n.trees=best_iter, type="response") / 
                       predict(m1_gbm,newdata = training_set,n.trees=best_iter, type="response") -1),
                 bins=60) + 
  xlab("Relative Difference") + ggtitle("Relative Difference between both models")
```






# Comparison with GAM

```{r, message=FALSE, warning=FALSE, fig.align='center', dpi = 500, tidy=TRUE, cache=TRUE}
## Group levels
# Variable Power
training_set$Power_merged=training_set$Power
levels(training_set$Power_merged) = list("A"= "d",
                                         "B" = c("e","f", "g", "h"),
                                         "C" = c("i","j", "k", "l", "m", "n", "o"))

#Variable Region
training_set$Region_merged = training_set$Region
levels(training_set$Region_merged)[c(1,5, 10)] ="R11-31-74"

#Variable Brand
training_set$Brand_merged = training_set$Brand
levels(training_set$Brand_merged) <- list("A" = c("Fiat","Mercedes, Chrysler or BMW",
                                                  "Opel, General Motors or Ford",
                                                  "other",
                                                  "Volkswagen, Audi, Skoda or Seat"),
                                          "B" = "Japanese (except Nissan) or Korean",
                                          "C" = "Renault, Nissan or Citroen")

require(parallel)
require(mgcv)
cl = makeCluster(3) # Number of cores to use
m0_bam = bam(ClaimNb ~ offset(log(Exposure)) + Power_merged  * Region_merged +  Brand_merged + Gas+Region_merged* Brand_merged+
               s(DriverAge)+s(CarAge),
         data = training_set,
         family=poisson(link = log),
         cluster = cl)
stopCluster(cl)
ggplot() + 
  geom_point(aes(x=predict(m0_bam, head(training_set, 500), type="response"),
                          y=predict(m0_gbm,newdata = head(training_set, 500),n.trees=best_iter, type="response") *head(training_set$Exposure, 500))) + 
  geom_abline(slope=1, intercept=0) + 
  xlab("GAM") + ylab("GBM")+coord_fixed()
```


## GAM vs GBM3

Assume that customers always choose the cheapest insurance price. Let's compare two insurance companies, one using GAM and one using GBM. We assume that the average cost of claim is equal for all policyholders.
```{r, warning=FALSE, tidy=TRUE}
pred = data.frame(gam = predict(m0_bam, training_set, type="response"),
                  gbm = predict(m0_gbm,newdata = training_set,n.trees=best_iter, type="response") * training_set$Exposure)

pred$company = 1*apply(pred, 1, function(x){x[1] == min(x[1], x[2])})

# Totals expected claims for company A and total observed claims
c(sum(pred$gam * pred$company), sum(pred$company * training_set$ClaimNb))
# Total expected claims for company B and total observed claims
c(sum(pred$gbm * (1-pred$company)), sum((1-pred$company) * training_set$ClaimNb)) 
```

## Final Remark

It may be required to correct the "intercept" of a gbm. Indeed, let us take at look at the total expected number of claims and compare it to the observed one. Let us do the same comparison with the GAM from above.
```{r}
# GAM
print(paste(c("GAM predicted ", "GAM  obs"),c(sum(pred$gam), sum(training_set$ClaimNb))))

print(paste(c("GBM predicted ", "GBM  obs"),c(sum(pred$gbm), sum(training_set$ClaimNb))))
```

GBM tend to underestimate the total number of claims. We could correct the claim frequency with 
```{r}
intercept_correction = sum(training_set$ClaimNb)/sum(pred$gbm)
intercept_correction
```

Let us do it, and recompute the error on the testing set, first without correction, then with correction.

```{r}
# Without correction

2*(sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb,log=TRUE))-
  sum(dpois(x = testing_set$ClaimNb, lambda = predict(m0_gbm,newdata = testing_set,n.trees=best_iter, type="response") * testing_set$Exposure,
            log=TRUE)))


# With correction

2*(sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb,log=TRUE))-
  sum(dpois(x = testing_set$ClaimNb, lambda = intercept_correction * predict(m0_gbm,newdata = testing_set,n.trees=best_iter, type="response") * testing_set$Exposure,
            log=TRUE)))
```

